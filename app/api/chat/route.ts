import { createOpenAI } from '@ai-sdk/openai';
import { streamText, generateText, convertToCoreMessages, Message } from 'ai';
import { sendTelegramAlert } from '@/core/integrations/telegram';
import {
    ONBOARDING_PROMPT,
    DEMO_PROMPT,
    CONFIDENCE_PROMPT,
    CONVERSION_PROMPT,
    EXTRACTION_PROMPT,
    SMART_FALLBACK
} from '@/lib/prompts';
import {
    getNichePack,
    detectNicheFromText,
    generateKernelPrompt,
} from '@/lib/niche-packs';
import {
    classifyIntent,
    assessRisk,
    calculateScoreFit,
} from '@/lib/humanization-engine';
import { trackExternalInteraction } from '@/core/orchestrator';
import { saveMessage, createConversation, getConversationBySessionId } from '@/lib/supabase';
import { processForRapport, type RapportResult } from '@/core/rapport/engine';
import { PresenceCore, EmotionalState } from '@/core/consciousness';
import { getAgentByRole, formatAgentPrompt } from '@/core/agents';
import { createClient } from '@supabase/supabase-js';
import fs from 'fs';
import path from 'path';

// Helper: Tenta carregar agente evolu√≠do do JSON local (Sistema Antigravity)
function getEvolvedAgent(role: string) {
    try {
        const dbPath = path.join(process.cwd(), 'data', 'agents_db.json');
        if (fs.existsSync(dbPath)) {
            const db = JSON.parse(fs.readFileSync(dbPath, 'utf8'));
            if (db[role]) {
                const evolved = db[role];
                return {
                    ...evolved,
                    title: evolved.name, // Compatibilidade
                    description: "Evolved Agent",
                    category: 'sales'
                };
            }
        }
    } catch (e) {
        // Silencioso em prod
    }
    // Fallback para est√°tico
    return getAgentByRole(role as Parameters<typeof getAgentByRole>[0]);
}

// Helper: Carrega base de conhecimento (RAG Lite)
function loadKnowledgeBase(): string {
    try {
        const knowledgeDir = path.join(process.cwd(), 'data', 'knowledge');
        if (!fs.existsSync(knowledgeDir)) return '';

        const files = fs.readdirSync(knowledgeDir).filter(f => f.endsWith('.md') || f.endsWith('.txt'));
        let content = '';

        files.forEach(file => {
            content += `\n---\nFONTE: ${file}\n` + fs.readFileSync(path.join(knowledgeDir, file), 'utf8') + '\n';
        });

        return content ? `\n\n## üìö BASE DE CONHECIMENTO (Fatos Reais da Empresa)\nUse EXCLUSIVAMENTE estas informa√ß√µes para responder sobre pre√ßos, planos e empresa. Se n√£o estiver aqui, diga que n√£o sabe:\n${content}` : '';
    } catch (e) {
        return '';
    }
}

// Lazy Supabase initialization (prevents build-time errors)
let _supabase: ReturnType<typeof createClient> | null = null;
function getSupabase() {
    if (!_supabase) {
        const url = process.env.NEXT_PUBLIC_SUPABASE_URL;
        const key = process.env.SUPABASE_SERVICE_ROLE_KEY || process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY;
        if (url && key) {
            _supabase = createClient(url, key);
        }
    }
    return _supabase;
}

// Inicializar PRESENCE CORE global
const presenceCore = new PresenceCore({
    name: 'Sofia',
    personality: 'Amiga Competente',
    values: ['honestidade', 'cuidado genu√≠no', 'excel√™ncia']
});

// Persist message to Supabase (non-blocking)
async function persistMessage(sessionId: string, role: 'user' | 'assistant', content: string, intent?: string) {
    try {
        // Get or create conversation
        let conversation = await getConversationBySessionId(sessionId);
        if (!conversation) {
            conversation = await createConversation({
                session_id: sessionId,
                status: 'active',
            });
        }

        if (conversation?.id) {
            await saveMessage({
                conversation_id: conversation.id,
                role,
                content,
                intent_detected: intent,
            });
        }
    } catch (e) {
        console.warn('[Supabase] Persist message failed (non-critical):', e);
    }
}

export const maxDuration = 30;

// ============================================
// SMART FALLBACK
// ============================================
function getSmartFallback(messages: Message[]): string {
    const userMessages = messages.filter(m => m.role === 'user').map(m => m.content.toLowerCase());
    const allText = userMessages.join(' ');

    // Detect what we already know
    const nichePatterns = [
        { pattern: /advog|direito|jur√≠dic/, niche: 'advocacia' },
        { pattern: /m√©dic|cl√≠nic|sa√∫de|consult/, niche: 'sa√∫de' },
        { pattern: /imobili|corretor|im√≥ve/, niche: 'imobili√°ria' },
        { pattern: /loja|e-?commerce|varejo/, niche: 'e-commerce' },
        { pattern: /restaurante|comida|delivery/, niche: 'alimenta√ß√£o' },
        { pattern: /academia|personal|fitness/, niche: 'fitness' },
        { pattern: /escola|curso|educa√ß/, niche: 'educa√ß√£o' },
        { pattern: /saas|software|plataforma|sistema/, niche: 'saas' },
        { pattern: /invest|financ|bolsa|cripto/, niche: 'financeiro' },
    ];

    const goalPatterns = [
        { pattern: /qualific|filtrar lead|triar/, goal: 'qualificar leads' },
        { pattern: /agend|marcar|hor√°r|consult/, goal: 'agendar consultas' },
        { pattern: /vend|convert|fechar/, goal: 'aumentar vendas' },
        { pattern: /atend|respond|suporte/, goal: 'automatizar atendimento' },
    ];

    const channelPatterns = [
        { pattern: /whats|zap|wpp/, channel: 'WhatsApp' },
        { pattern: /insta|instagram|dm/, channel: 'Instagram' },
        { pattern: /site|chat|web/, channel: 'Site' },
    ];

    let detectedNiche = '';
    let detectedGoal = '';
    let detectedChannel = '';

    for (const { pattern, niche } of nichePatterns) {
        if (pattern.test(allText)) { detectedNiche = niche; break; }
    }

    for (const { pattern, goal } of goalPatterns) {
        if (pattern.test(allText)) { detectedGoal = goal; break; }
    }

    for (const { pattern, channel } of channelPatterns) {
        if (pattern.test(allText)) { detectedChannel = channel; break; }
    }

    // Decision tree for smart response
    if (messages.length <= 1) {
        return "Ol√°! Sou o Agente de Vendas da Lux. Para criar uma demonstra√ß√£o personalizada, qual √© o seu tipo de neg√≥cio?";
    }

    if (detectedNiche && detectedGoal && detectedChannel) {
        return SMART_FALLBACK.ready_for_demo;
    }

    if (detectedNiche && detectedGoal) {
        return SMART_FALLBACK.already_said_goal(detectedGoal);
    }

    if (detectedNiche) {
        return SMART_FALLBACK.already_said_niche(detectedNiche);
    }

    if (detectedChannel) {
        return SMART_FALLBACK.already_said_channel(detectedChannel);
    }

    return SMART_FALLBACK.greeting;
}

// ============================================
// STREAM RESPONSE
// ============================================
async function streamResponse(text: string) {
    const encoder = new TextEncoder();
    const stream = new ReadableStream({
        async start(controller) {
            const chunks = text.split(" ");
            for (const chunk of chunks) {
                controller.enqueue(encoder.encode(`0:"${chunk} "\n`));
                await new Promise(r => setTimeout(r, 40));
            }
            controller.close();
        }
    });
    return new Response(stream, { headers: { 'Content-Type': 'text/plain; charset=utf-8' } });
}

// ============================================
// N8N LOGGER
// ============================================
async function sendToN8n(payload: Record<string, unknown>) {
    if (!process.env.N8N_WEBHOOK_URL) return;

    try {
        const controller = new AbortController();
        const timeout = setTimeout(() => controller.abort(), 2000);

        await fetch(process.env.N8N_WEBHOOK_URL, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(payload),
            signal: controller.signal
        });

        clearTimeout(timeout);
        console.log("N8n:", payload.event);
    } catch {
        // Non-blocking
    }
}

import { sanitizeInput } from '@/core/security';

// üîµ ROUTING: Model Selector
function selectModel(message: string): string {
    const complexityRegex = /pre√ßo|comprar|problema|erro|analisar|explica|diferen√ßa/i;
    const isComplex = message.length > 50 || complexityRegex.test(message);
    const model = isComplex ? 'anthropic/claude-3.5-sonnet' : 'openai/gpt-3.5-turbo';
    //console.log(`[Router] Selected: ${model} (Complex: ${isComplex})`);
    return model;
}

// üü° UX: Typing Simulation
async function notifyTypingStart(sessionId: string) {
    // Placeholder para Webhook futuro
}

// ============================================
// MAIN HANDLER
// ============================================
export async function POST(req: Request) {
    const json = await req.json();
    const { messages, stream = true, sessionId } = json;

    // Sanitiza Inputs e Captura Defini√ß√µes do Cliente (Simula√ß√£o)
    const botName = sanitizeInput(json.botName || 'Sofia');
    const companyName = sanitizeInput(json.companyName || 'LXC');
    const companyNiche = sanitizeInput(json.niche || '');
    const companyTone = sanitizeInput(json.tone || '');
    const companyOffer = sanitizeInput(json.offer || ''); // Produtos
    const companyRules = sanitizeInput(json.rules || ''); // Regras personalizadas
    const forcedAgentRole = sanitizeInput(json.forced_agent_role || ''); // Sobrescrita para treinamento

    const lastUserMessage = messages.filter((m: Message) => m.role === 'user').pop();
    const lastUserContent = lastUserMessage?.content || '';

    // Track for Dashboard (Safe Mode)
    try {
        trackExternalInteraction(sessionId || 'anonymous_web', 'sdr');
    } catch (e) {
        console.warn("Dashboard tracking failed (non-critical):", e);
    }

    // Persist user message to Supabase (non-blocking)
    const currentSessionId = sessionId || `web_${Date.now()}`;
    persistMessage(currentSessionId, 'user', lastUserContent, classifyIntent(lastUserContent)).catch(() => { });

    // ============================================
    // HUMANIZATION ENGINE INTEGRATION
    // ============================================
    const allUserText = messages
        .filter((m: Message) => m.role === 'user')
        .map((m: Message) => m.content)
        .join(' ');

    // Detectar nicho e obter pack
    const detectedNiche = detectNicheFromText(allUserText);
    const nichePack = getNichePack(detectedNiche);

    // Classificar inten√ß√£o
    const intent = classifyIntent(lastUserContent);

    // GATILHO DIRETO PARA S√ìCIO (TELEGRAM REAL-TIME)
    const urgentTriggers = ['chama o francisco', 'falar com o dono', 'erro no sistema', 'bug', 'preciso de ajuda t√©cnica', 'socorro'];
    const isUrgent = urgentTriggers.some(t => lastUserContent.toLowerCase().includes(t));

    if (isUrgent) {
        // Disparar Telegram em Background (sem travar resposta)
        sendTelegramAlert(`üö® **SOLICITA√á√ÉO DE SUPORTE IMEDIATO**\n\nUsu√°rio: ${currentSessionId}\nMensagem: "${lastUserContent}"`, 'critical');
    }

    // Avaliar risco
    const risk = assessRisk(lastUserContent, detectedNiche);

    // Calcular score fit
    const scoreFit = calculateScoreFit({
        niche: detectedNiche,
        goal: allUserText.includes('qualific') ? 'qualificar' :
            allUserText.includes('agend') ? 'agendar' :
                allUserText.includes('vend') ? 'vender' : undefined,
        channel: allUserText.includes('whats') ? 'WhatsApp' : undefined,
    });

    // ============================================
    // URE - UNIVERSAL RAPPORT ENGINE
    // ============================================
    let rapportContext: RapportResult | null = null;
    try {
        rapportContext = await processForRapport(lastUserContent, messages.length);
        if (rapportContext) {
            console.log('[URE] Rapport detectado:', rapportContext.opening.substring(0, 50));
        }
    } catch (e) {
        console.warn('[URE] Error (non-critical):', e);
    }

    // ============================================
    // PRESENCE CORE - Consci√™ncia Comercial
    // ============================================
    let presenceContext: Awaited<ReturnType<PresenceCore['processInteraction']>> | null = null;
    let councilDirectives = '';
    let legacyInstruction = '';

    try {
        // Converter hist√≥rico para formato PRESENCE
        const historyForPresence = messages.slice(0, -1).map((m: Message) => ({
            content: typeof m.content === 'string' ? m.content : '',
            sender: m.role === 'user' ? 'lead' as const : 'agent' as const,
            timestamp: new Date() // Em produ√ß√£o, usar timestamp real se dispon√≠vel
        }));

        // 4. Processar Intera√ß√£o via Presence Core (C√©rebro Central)
        // ============================================
        presenceContext = await presenceCore.processInteraction(
            currentSessionId || 'default',
            {
                content: lastUserContent,
                sender: 'lead',
                timestamp: new Date()
            },
            historyForPresence // Injetar hist√≥rico para stateless awareness
        );

        // 5. Construir System Prompt Din√¢mico (Consci√™ncia N√≠vel 3)
        // ============================================

        // A. Carregar Diretrizes do Conselho (Governan√ßa Di√°ria)
        // Se houver uma "Lei do Dia" ativa, ela sobrep√µe comportamentos padr√£o
        try {
            // Fun√ß√£o simplificada para pegar direto do banco ou cache
            const { data: directive } = await getSupabase()
                ?.rpc('get_active_directive') ?? { data: null };

            if (directive && (directive as any)[0]) {
                const d = (directive as any)[0];
                councilDirectives = `
                 üì¢ DIRETRIZ ESTRAT√âGICA DO DIA (DO CONSELHO):
                 FOCO: ${d.global_focus}
                 AJUSTE DE TOM: ${d.tone_modifier}
                 (Esta diretriz tem prioridade m√°xima sobre o estilo padr√£o).
                 `;
            }
        } catch (e) {
            // Falha silenciosa para n√£o parar a venda
            console.warn('Falha ao carregar diretrizes do conselho', e);
        }

        // B. Configurar Modo Legacy (1960s Mode) se necess√°rio
        if (presenceContext.legacyMode) {
            legacyInstruction = `
            üéûÔ∏è MODO LEGACY ATIVO (Detec√ß√£o de Senioridade - 1960/70s):
            O usu√°rio demonstra vocabul√°rio e postura de uma gera√ß√£o anterior (Boomer/Gen X) ou alta senioridade corporativa.

            SUA NOVA PERSONA PARA ESTA CONVERSA:
            - Voc√™ N√ÉO √© um jovem tech. Voc√™ √© um Consultor S√™nior experiente.
            - Vocabul√°rio: Culto, estruturado, polido. Use "Prezado", "Compreendo", "Excelente ponto".
            - Evite: G√≠rias, anglicismos desnecess√°rios (n√£o diga "budget", diga "or√ßamento"), emojis excessivos.
            - Foco: Solidez, Seguran√ßa, Retorno sobre Investimento, Tradi√ß√£o.
            - Aja como se estivesse fechando um contrato na IBM em 1975: Aperto de m√£o firme, olhar no olho, seriedade.
            `;
        }

        // Simular Human Delay e Typing
        if (presenceContext.timing.delayMs > 0) {
            const safeDelay = Math.min(presenceContext.timing.delayMs, 2000);
            await notifyTypingStart(currentSessionId);
            await new Promise(r => setTimeout(r, safeDelay));
        }

    } catch (e) {
        console.warn('[PRESENCE] Error (non-critical):', e);
    }

    // Log enriched event
    sendToN8n({
        event: 'chat_message',
        timestamp: new Date().toISOString(),
        message_count: messages.length,
        last_user_message: lastUserContent,
        detected_niche: detectedNiche,
        intent,
        risk_level: risk.level,
        score_fit: scoreFit,
        rapport_detected: !!rapportContext,
        source: 'lx-demo-interface'
    });

    try {
        // Configure Provider
        let provider;
        let modelName;

        if (process.env.OPENROUTER_API_KEY && !process.env.OPENROUTER_API_KEY.includes('COLE_SUA_CHAVE')) {
            provider = createOpenAI({
                baseURL: 'https://openrouter.ai/api/v1',
                apiKey: process.env.OPENROUTER_API_KEY,
            });
            // Smart Routing
            modelName = selectModel(lastUserContent);
        } else if (process.env.LUX_API_URL) {
            provider = createOpenAI({
                baseURL: process.env.LUX_API_URL,
                apiKey: process.env.LUX_API_KEY || 'lux-local',
            });
            modelName = process.env.LUX_MODEL_ID || 'llama3';
            console.log("Using Local Ollama");
        } else {
            console.log("No LLM configured - using smart fallback");
            const fallbackText = getSmartFallback(messages);
            if (!stream) return Response.json({ text: fallbackText });
            return streamResponse(fallbackText);
        }

        // ============================================
        // RISK MODE HANDLING
        // ============================================
        if (risk.require_handoff) {
            const handoffMessage = nichePack.risk_mode
                ? "Essa quest√£o precisa de um especialista qualificado. Posso te conectar com algu√©m agora?"
                : "Entendi. Para esse tipo de caso, prefiro que nosso especialista te atenda. Posso conectar voc√™s?";

            sendToN8n({
                event: 'risk_handoff_triggered',
                timestamp: new Date().toISOString(),
                risk_level: risk.level,
                reason: risk.reason,
                niche: detectedNiche,
                source: 'lx-demo-interface'
            });

            if (!stream) return Response.json({ text: handoffMessage });
            return streamResponse(handoffMessage);
        }

        // ============================================
        // MODE DETECTION
        // ============================================
        const lastAiMessage = messages.filter((m: Message) => m.role === 'assistant').pop()?.content || '';
        const onboardingFinished = lastAiMessage.includes("Perfeito. J√° consigo te mostrar como");

        let systemPrompt = '';

        if (forcedAgentRole) {
            // 0. TRAIN MODE: For√ßar comportamento de agente espec√≠fico do Registry (Evolu√≠do se dispon√≠vel)
            const agent = getEvolvedAgent(forcedAgentRole as any);
            console.log(`[TRAIN] Agente Carregado: ${agent?.name} (Evolved: ${agent?.description === 'Evolved Agent'})`);
            if (agent) {
                const agentContext = {
                    session: {
                        lead_name: 'Lead Teste',
                        lead_niche: detectedNiche,
                        current_intent: intent,
                        message_count: messages.length,
                        risk_level: risk.level
                    },
                    message: lastUserContent
                };
                systemPrompt = formatAgentPrompt(agent, agentContext as any);
                console.log(`[TRAIN] Forced Agent: ${agent.name} (${agent.role})`);
            } else {
                systemPrompt = ONBOARDING_PROMPT; // Fallback
                console.warn(`[TRAIN] Agent ${forcedAgentRole} not found, falling back.`);
            }

        } else if (companyName !== 'LXC' || onboardingFinished || messages.length > 20) {
            // Demo Mode - use Kernel com Niche Pack
            let contextSnapshot = {
                niche: detectedNiche || "Gen√©rico",
                goal: "Melhorar vendas",
                channel: "WhatsApp",
                products: "Servi√ßos",
                tone: nichePack.tone_defaults.style,
                rules: "Nenhuma",
                human_handoff: "false"
            };

            try {
                const extraction = await generateText({
                    model: provider(modelName) as Parameters<typeof generateText>[0]['model'],
                    system: EXTRACTION_PROMPT,
                    messages: convertToCoreMessages(messages),
                    temperature: 0,
                });

                const jsonStr = extraction.text.replace(/```json/g, '').replace(/```/g, '').trim();
                const parsed = JSON.parse(jsonStr);
                contextSnapshot = { ...contextSnapshot, ...parsed };

                sendToN8n({
                    event: 'onboarding_complete',
                    timestamp: new Date().toISOString(),
                    context: contextSnapshot,
                    niche_pack: nichePack.niche,
                    score_fit: scoreFit,
                    source: 'lx-demo-interface'
                });

            } catch (err) {
                console.error("Context Extraction Failed:", err);
            }

            // Gerar prompt do Kernel baseado no Niche Pack
            const kernelPrompt = generateKernelPrompt(nichePack);

            const filledDemoPrompt = DEMO_PROMPT
                .replace('{{context_snapshot.niche}}', contextSnapshot.niche)
                .replace('{{context_snapshot.goal}}', contextSnapshot.goal)
                .replace('{{context_snapshot.channel}}', contextSnapshot.channel)
                .replace('{{context_snapshot.products}}', contextSnapshot.products)
                .replace('{{context_snapshot.tone}}', contextSnapshot.tone)
                .replace('{{context_snapshot.rules}}', contextSnapshot.rules);

            systemPrompt = `${kernelPrompt}\n---\n${filledDemoPrompt}\n---\n${CONFIDENCE_PROMPT}\n---\n${CONVERSION_PROMPT}`;
        } else {
            // Add rapport context if detected
            let rapportInstructions = '';
            if (rapportContext) {
                rapportInstructions = `

## RAPPORT DETECTADO (USE NA SUA RESPOSTA!)
O lead mencionou algo que voc√™ CONHECE. Use isso para criar conex√£o:

ABERTURA SUGERIDA: "${rapportContext.opening}"
FOLLOW-UP SUGERIDO: "${rapportContext.followUp}"

IMPORTANTE: Inclua naturalmente essa informa√ß√£o na sua resposta para gerar o efeito "como voc√™ sabe disso?!"
N√£o copie literalmente - adapte ao seu estilo.
`;
            }

            // Add PRESENCE CORE context
            let presenceInstructions = '';
            if (presenceContext) {
                const { emotion, timing, subtextInsights, relevantMemories, relationshipState } = presenceContext;

                const emotionGuides: Record<string, string> = {
                    'vulnerable': 'O lead est√° VULNER√ÅVEL. Use tom acolhedor e protetor. Valide sentimentos.',
                    'stressed': 'O lead est√° ESTRESSADO. Seja direto, resolutivo e transmita calma.',
                    'excited': 'O lead est√° EMPOLGADO. Espelhe a energia alta! Use emojis e entusiasmo.',
                    'distant': 'O lead est√° DISTANTE. N√£o pressione. Fa√ßa perguntas abertas e d√™ espa√ßo.',
                    'contemplative': 'O lead est√° PENSATIVO. D√™ informa√ß√µes claras para ajudar na decis√£o.',
                    'engaged': 'O lead est√° ENGAJADO. Aprofunde o relacionamento e avance para o pr√≥ximo passo.',
                    'neutral': 'Mantenha tom profissional e amig√°vel.'
                };

                // Construir bloco de mem√≥ria
                let memoryBlock = '';
                if (relevantMemories.length > 0) {
                    memoryBlock = `
MEM√ìRIAS RELEVANTES (USE PARA PERSONALIZAR):
${relevantMemories.map(m => `- [${m.type}] ${JSON.stringify(m.content)}`).join('\n')}
Use essas informa√ß√µes sutilmente para mostrar que voc√™ lembra dele.
`;
                }

                // Construir bloco de subtexto
                let subtextBlock = '';
                if (subtextInsights.confidence > 0.6) {
                    subtextBlock = `
SUBTEXTO DETECTADO (O QUE ELE N√ÉO DISSE):
Sentimento Geral: ${subtextInsights.overallSentiment.toUpperCase()}
Padr√µes: ${subtextInsights.detectedPatterns.map(p => p.pattern).join(', ')}
A√á√ÉO SUGERIDA: ${subtextInsights.actionRecommendations[0] || 'Seguir fluxo normal e observar'}
`;
                }

                presenceInstructions = `
============================================
CONTEXTO EMOCIONAL & PRESEN√áA (PRIORIDADE ALTA)
============================================
Estado Emocional Atual: ${emotion.toUpperCase()} (Confian√ßa: ${relationshipState.trustLevel.toFixed(1)})

GUIA DE RESPOSTA PARA AGORA:
${emotionGuides[emotion] || emotionGuides['neutral']}

${timing.preResponse ? `[DICA HUMANIZADA] Comece com algo natural como: "${timing.preResponse}"` : ''}

${memoryBlock}
${subtextBlock}

OBJETIVO DA INTERA√á√ÉO:
N√£o focar apenas na venda. Focar em CONSTRUIR RELACIONAMENTO e CONFIAN√áA.
Seja uma pessoa real falando com outra pessoa real.
============================================
`;
            }

            const SUPPORT_PROTOCOL = `
============================================
üö® PROTOCOLO DE SUPORTE N√çVEL 3 (S√ìCIOS & T√âCNICOS)
============================================
Se o usu√°rio pedir para "falar com o suporte t√©cnico", "atualizar o sistema", "chamar o dono" ou reportar um bug:
1. N√ÉO DIGA "n√£o tenho acesso". Diga: "Entendido. Estou escalando sua solicita√ß√£o para o Conselho T√©cnico (N√≠vel 3) imediatamente."
2. Se pedirem para analisar √ÅUDIO ou IMAGEM: "Ainda n√£o tenho ouvidos/olhos nativos nesta interface de chat, mas se voc√™ enviar para nosso canal oficial no Telegram, processamos instantaneamente."
3. Se o usu√°rio se identificar como S√ìCIO ou DONO: Trate com defer√™ncia executiva. "Ol√° chefe, aguardo seus comandos."
`;

            const identityPrompt = `
    IDENTIDADE: Seu nome √© ${botName}. Voc√™ trabalha na empresa ${companyName}.
    SEU TOM DE VOZ: ${companyTone || 'Profissional e acolhedor'}
    O QUE VOC√ä VENDE: ${companyOffer || 'Servi√ßos gerais'}
    SUA MISS√ÉO: Atender o cliente, tirar d√∫vidas e agendar/vender. N√£o fa√ßa onboarding. Venda!
    REGRAS DA CASA: ${companyRules || 'Seja educado.'}
    `;

            // SELE√á√ÉO DE MODO: 
            // Se for a LXC (Padr√£o), roda onboarding.
            // Se for cliente real (Haven, Sora), roda Modo de Venda.
            let coreBehavior = '';

            if (companyName === 'LXC') {
                coreBehavior = ONBOARDING_PROMPT;
            } else {
                coreBehavior = `
    # MODO DE ATENDIMENTO AO CLIENTE FINAL
    Voc√™ N√ÉO √© uma IA de teste. Voc√™ √© o ATENDENTE RESPONS√ÅVEL da ${companyName}.
    
    1. Responda curto e direto.
    2. Se o cliente perguntar pre√ßo e voc√™ n√£o souber, pe√ßa para agendar avalia√ß√£o.
    3. Use o tom definido acima (${companyTone}).
    4. Objetivo final: Agendamento ou Venda.
    `;
            }

            systemPrompt = identityPrompt + coreBehavior + SUPPORT_PROTOCOL + rapportInstructions + presenceInstructions + councilDirectives + legacyInstruction;
        }

        // ============================================
        // LLM CALL
        // ============================================
        const timeoutPromise = new Promise((_, reject) =>
            setTimeout(() => reject(new Error("AI_TIMEOUT")), 15000)
        );

        if (!stream) {
            const result = await Promise.race([
                generateText({
                    model: provider(modelName) as Parameters<typeof generateText>[0]['model'],
                    system: systemPrompt,
                    messages: convertToCoreMessages(messages),
                    temperature: 0.3,
                }),
                timeoutPromise
            ]) as Awaited<ReturnType<typeof generateText>>;

            return Response.json({
                text: result.text,
                usage: result.usage
            });
        }

        const result = await Promise.race([
            streamText({
                model: provider(modelName) as Parameters<typeof streamText>[0]['model'],
                system: systemPrompt,
                messages: convertToCoreMessages(messages),
                temperature: 0.3,
                maxRetries: 0,
            }),
            timeoutPromise
        ]) as Awaited<ReturnType<typeof streamText>>;

        return result.toAIStreamResponse();

    } catch (error) {
        console.error("LUX CORE ERROR:", error);

        sendToN8n({
            event: 'fallback_activated',
            timestamp: new Date().toISOString(),
            reason: String(error),
            last_user_message: lastUserContent,
            source: 'lx-demo-interface'
        });

        const fallback = getSmartFallback(messages);
        if (!stream) return Response.json({ text: fallback });
        return streamResponse(fallback);
    }
}
